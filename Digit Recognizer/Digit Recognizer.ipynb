{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import numpy library\n",
    "import numpy as np\n",
    "\n",
    "# numpy array\n",
    "array = [[1,2,3],[4,5,6]]\n",
    "first_array = np.array(array) # 2x3 array\n",
    "print(\"Array Type: {}\".format(type(first_array))) # type\n",
    "print(\"Array Shape: {}\".format(np.shape(first_array))) # shape\n",
    "print(first_array)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import pytorch library\n",
    "import torch\n",
    "\n",
    "# pytorch array\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import pytorch library\n",
    "import torch\n",
    "\n",
    "# pytorch array\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# numpy random\n",
    "print(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# numpy random\n",
    "print(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# random numpy array\n",
    "array = np.random.rand(2,2)\n",
    "print(\"{} {}\\n\".format(type(array),array))\n",
    "\n",
    "# from numpy to tensor\n",
    "from_numpy_to_tensor = torch.from_numpy(array)\n",
    "print(\"{}\\n\".format(from_numpy_to_tensor))\n",
    "\n",
    "# from tensor to numpy\n",
    "tensor = from_numpy_to_tensor\n",
    "from_tensor_to_numpy = tensor.numpy()\n",
    "print(\"{} {}\\n\".format(type(from_tensor_to_numpy),from_tensor_to_numpy))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# create tensor \n",
    "tensor = torch.ones(3,3)\n",
    "print(\"\\n\",tensor)\n",
    "\n",
    "print(\"{}--{}\\n\".format(tensor.view(9).shape, tensor.view(9)))\n",
    "\n",
    "print(\"Addition: {}\\n\".format(torch.add(tensor,tensor)))\n",
    "\n",
    "print(\"Subtraction: {}\\n\".format(tensor.sub(tensor)))\n",
    "\n",
    "print(\"Element wise multiplication: {}\\n\".format(torch.mul(tensor,tensor)))\n",
    "\n",
    "\n",
    "print(\"Element wise division: {}\\n\".format(torch.div(tensor,tensor)))\n",
    "\n",
    "\n",
    "tensor = torch.Tensor([1,2,3,4,5])\n",
    "print(\"Mean: {}\".format(tensor.mean()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "var = Variable(torch.ones(3), requires_grad=True)\n",
    "var"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "array = [2,4]\n",
    "tensor = torch.Tensor(array)\n",
    "x = Variable(tensor, requires_grad = True)\n",
    "y = x**2\n",
    "print(\" y =  \",y)\n",
    "\n",
    "# recap o equation o = 1/2*sum(y)\n",
    "o = (1/2)*sum(y)\n",
    "print(\" o =  \",o)\n",
    "\n",
    "# backward\n",
    "o.backward() # calculates gradients\n",
    "\n",
    "# As I defined, variables accumulates gradients. In this part there is only one variable x.\n",
    "# Therefore variable x should be have gradients\n",
    "# Lets look at gradients with x.grad\n",
    "print(\"gradients: \",x.grad)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train = pd.read_csv(r\"train.csv\",dtype = np.float32)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "targets_numpy = train.label.values\n",
    "targets_numpy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_numpy = train.loc[:, train.columns != \"label\"].values / 255"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_numpy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features_train, features_test, targets_train, targets_test = train_test_split(feature_numpy, targets_numpy, test_size = 0.2, random_state = 42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print('num_epochs: {}'.format(num_epochs))\n",
    "\n",
    "trian = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "trian_loader = DataLoader(dataset = trian, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.imshow(feature_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegressionModel(input_dim=28*28, output_dim=10)\n",
    "\n",
    "\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "model.parameters()\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "print('num_epochs: {}'.format(num_epochs))\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trian_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-20250715",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
