{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <class 'numpy.ndarray'>\n",
      "Array Shape: (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# import numpy library\n",
    "import numpy as np\n",
    "\n",
    "# numpy array\n",
    "array = [[1,2,3],[4,5,6]]\n",
    "first_array = np.array(array) # 2x3 array\n",
    "print(\"Array Type: {}\".format(type(first_array))) # type\n",
    "print(\"Array Shape: {}\".format(np.shape(first_array))) # shape\n",
    "print(first_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <built-in method type of Tensor object at 0x00000189213C9A80>\n",
      "Array Shape: torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# import pytorch library\n",
    "import torch\n",
    "\n",
    "# pytorch array\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <built-in method type of Tensor object at 0x00000189213908B0>\n",
      "Array Shape: torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# import pytorch library\n",
    "import torch\n",
    "\n",
    "# pytorch array\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy [[0.44751894 0.21200703 0.08845692]\n",
      " [0.32351338 0.24573735 0.64401825]]\n",
      "\n",
      "tensor([[0.0165, 0.2279, 0.8560],\n",
      "        [0.2199, 0.8271, 0.7782]])\n"
     ]
    }
   ],
   "source": [
    "# numpy random\n",
    "print(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy [[0.66205671 0.0821012  0.76526178]\n",
      " [0.8274459  0.55263165 0.3728339 ]]\n",
      "\n",
      "tensor([[0.0424, 0.6974, 0.3238],\n",
      "        [0.7834, 0.7361, 0.9764]])\n"
     ]
    }
   ],
   "source": [
    "# numpy random\n",
    "print(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n",
    "\n",
    "# pytorch random\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.20251222 0.58293519]\n",
      " [0.85977281 0.53266202]]\n",
      "\n",
      "tensor([[0.2025, 0.5829],\n",
      "        [0.8598, 0.5327]], dtype=torch.float64)\n",
      "\n",
      "<class 'numpy.ndarray'> [[0.20251222 0.58293519]\n",
      " [0.85977281 0.53266202]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random numpy array\n",
    "array = np.random.rand(2,2)\n",
    "print(\"{} {}\\n\".format(type(array),array))\n",
    "\n",
    "# from numpy to tensor\n",
    "from_numpy_to_tensor = torch.from_numpy(array)\n",
    "print(\"{}\\n\".format(from_numpy_to_tensor))\n",
    "\n",
    "# from tensor to numpy\n",
    "tensor = from_numpy_to_tensor\n",
    "from_tensor_to_numpy = tensor.numpy()\n",
    "print(\"{} {}\\n\".format(type(from_tensor_to_numpy),from_tensor_to_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([9])--tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Addition: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n",
      "Subtraction: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Element wise multiplication: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Element wise division: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Mean: 3.0\n"
     ]
    }
   ],
   "source": [
    "# create tensor \n",
    "tensor = torch.ones(3,3)\n",
    "print(\"\\n\",tensor)\n",
    "\n",
    "print(\"{}--{}\\n\".format(tensor.view(9).shape, tensor.view(9)))\n",
    "\n",
    "print(\"Addition: {}\\n\".format(torch.add(tensor,tensor)))\n",
    "\n",
    "print(\"Subtraction: {}\\n\".format(tensor.sub(tensor)))\n",
    "\n",
    "print(\"Element wise multiplication: {}\\n\".format(torch.mul(tensor,tensor)))\n",
    "\n",
    "\n",
    "print(\"Element wise division: {}\\n\".format(torch.div(tensor,tensor)))\n",
    "\n",
    "\n",
    "tensor = torch.Tensor([1,2,3,4,5])\n",
    "print(\"Mean: {}\".format(tensor.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "var = Variable(torch.ones(3), requires_grad=True)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y =   tensor([ 4., 16.], grad_fn=<PowBackward0>)\n",
      " o =   tensor(10., grad_fn=<MulBackward0>)\n",
      "gradients:  tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "array = [2,4]\n",
    "tensor = torch.Tensor(array)\n",
    "x = Variable(tensor, requires_grad = True)\n",
    "y = x**2\n",
    "print(\" y =  \",y)\n",
    "\n",
    "# recap o equation o = 1/2*sum(y)\n",
    "o = (1/2)*sum(y)\n",
    "print(\" o =  \",o)\n",
    "\n",
    "# backward\n",
    "o.backward() # calculates gradients\n",
    "\n",
    "# As I defined, variables accumulates gradients. In this part there is only one variable x.\n",
    "# Therefore variable x should be have gradients\n",
    "# Lets look at gradients with x.grad\n",
    "print(\"gradients: \",x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"train.csv\",dtype = np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 7., 6., 9.], shape=(42000,), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_numpy = train.label.values\n",
    "targets_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_numpy = train.loc[:, train.columns != \"label\"].values / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(42000, 784), dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, targets_train, targets_test = train_test_split(feature_numpy, targets_numpy, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs: 29\n"
     ]
    }
   ],
   "source": [
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print('num_epochs: {}'.format(num_epochs))\n",
    "\n",
    "trian = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_loader = DataLoader(dataset = trian, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(feature_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001895216D9A0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegressionModel(input_dim=28*28, output_dim=10)\n",
    "\n",
    "\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "model.parameters()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs: 29\n",
      "Iteration: 500  Loss: 1.8157622814178467  Accuracy: 66.63095092773438%\n",
      "Iteration: 1000  Loss: 1.6077629327774048  Accuracy: 75.0952377319336%\n",
      "Iteration: 1500  Loss: 1.2959938049316406  Accuracy: 77.94047546386719%\n",
      "Iteration: 2000  Loss: 1.2130640745162964  Accuracy: 79.63095092773438%\n",
      "Iteration: 2500  Loss: 1.035719633102417  Accuracy: 80.83333587646484%\n",
      "Iteration: 3000  Loss: 0.942941427230835  Accuracy: 81.75%\n",
      "Iteration: 3500  Loss: 0.8997929096221924  Accuracy: 82.38095092773438%\n",
      "Iteration: 4000  Loss: 0.748491108417511  Accuracy: 82.89286041259766%\n",
      "Iteration: 4500  Loss: 0.9768815040588379  Accuracy: 83.44047546386719%\n",
      "Iteration: 5000  Loss: 0.7973506450653076  Accuracy: 83.76190185546875%\n",
      "Iteration: 5500  Loss: 0.7509477734565735  Accuracy: 84.19047546386719%\n",
      "Iteration: 6000  Loss: 0.8714340329170227  Accuracy: 84.61904907226562%\n",
      "Iteration: 6500  Loss: 0.6579304337501526  Accuracy: 84.78571319580078%\n",
      "Iteration: 7000  Loss: 0.7082140445709229  Accuracy: 84.95237731933594%\n",
      "Iteration: 7500  Loss: 0.6386493444442749  Accuracy: 85.11904907226562%\n",
      "Iteration: 8000  Loss: 0.7389987111091614  Accuracy: 85.3452377319336%\n",
      "Iteration: 8500  Loss: 0.5461099147796631  Accuracy: 85.57142639160156%\n",
      "Iteration: 9000  Loss: 0.6615358591079712  Accuracy: 85.69047546386719%\n",
      "Iteration: 9500  Loss: 0.5250820517539978  Accuracy: 85.82142639160156%\n"
     ]
    }
   ],
   "source": [
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "print('num_epochs: {}'.format(num_epochs))\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trian_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-20250715",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
